# Introduction

---

# Introduction

---

## Sommaire

- [Retour sur l’exercice](#part0)
- [Vocabulaires et ontologies](#part1)
- [Le protocole et le langage de requête SPARQL](#part2)
- [Notation SPARQL](#part3)
- [TP SPARQL](#part4)
- [Florilège d’applications du Linked Open Data](#part5)

---

name: part0

## Retour sur l’exercice

???

La plateforme d’édition scientifique Persée offre depuis 2017 un accès à ses données sous forme de données liées. Cet entrepôt de données présente l’avantage de proposer une interface (Sparklis) qui ne demande aucune connaissance informatique particulière pour formuler des requêtes et obtenir des listes de résultats.

L’objectif de cet exercice est de construire une requête avec ce service afin de télécharger un jeu de données pour vous familiariser avec l’utilisation des jeux de données liées.

1. Prendre connaissance de la [documentation](http://data.persee.fr/ressources/le-triplestore-de-persee/) et du [schéma de données](http://data.persee.fr/explorer/schemas-de-donnees/)
2. Au besoin, et au fur et à mesure de votre travail, vous pourrez avoir recours aux tutoriaux vidéos http://data.persee.fr/ressources/tutoriels/ ou à leur version textuelle http://data.persee.fr/ressources/tutoriels-texte/
3. Construire les requêtes suivantes et observez les résultats
   - Tous les documents qui ont pour auteur "Lepetit", listés par date d’édition décroissante
   - Chercher ses co-auteurs
   - Faite une liste des auteurs par document
   - Ordonner cette liste de documents par date de publication croissante
   - Lister les auteurs qui ont le plus de co-auteurs
   - Inventer une requête de votre choix
4. Pour chacune des requêtes, visualisez à chaque fois sa version SPARQL (cliquez sur "YASGUI view" en haut de la fenêtre) et essayer de comprendre à quoi celle-ci correspond
5. **Question bonus :** Essayer de modifier la dernière requête en SPARQL pour afficher les titres d’articles.

---

## La plate forme Persée

- http://www.persee.fr
- http://www.persee.fr/entrepot-oai
- http://data.persee.fr

### Autre exemple

- https://co-shs.ca

???

Persée est un programme national de numérisation et de diffusion de collections de documents scientifiques. Par l’intermédiaire de sa plateforme en ligne persée.fr, le site diffuse le texte et les métadonnées de plus de 600 000 documents scientifiques principalement issus de numérisation rétrospectives.

Les interfaces de recherche du service web permet d’explorer plusieurs index et sont munies de fonctionnalités de tri et de facettes qui permettent aux utilisateurs de faire des requêtes avancées dans la base de données. Néanmoins, celles-ci n’offrent que des possibilités de requêtes complexes et ne permettent pas les recherches croisées.

- entrepôt OAI-PMH
- mais phénomène de silos cf. ce qui a été évoqué la dernière fois

Or, l’équipe de Persée explique qu’elle recevait un nombre grandissant de demandes de chercheurs qui considérait le fond non plus comme une bibliothèque de documents mais comme un corpus de recherche à part entière.

- Manière d’envisager le corpus qui supposait donc d’ajouter au corpus des outils de parcours et de requête plus élaborés que ceux disponibles sur le portail
- Diversité de la documentation présente sur le site pour laquelle les technologies du web sémantiques apportait une réponse appropriée

Contexte par rapport à [OpenEdition](https://www.openedition.org) et le consortium [Érudit](https://www.erudit.org/en/). 

Démarche comparable avec la cyberinfrastructure en sciences humaines et sociales [CO-SHS](https://co-shs.ca)

---

## Schéma de données de data.persee.fr

http://data.persee.fr/explorer/schemas-de-donnees/

---

## Alignements de data.persee.fr

http://info.persee.fr/lalignement-des-autorites-persee-au-referentiel-idref/

---

Construire les requêtes suivantes et observez les résultats

- Tous les documents qui ont pour auteur "Lepetit", listés par date d’édition décroissante
- Chercher ses co-auteurs
- Faite une liste des auteurs par document
- Ordonner cette liste de documents par date de publication croissante
- Lister les auteurs qui ont le plus de co-auteurs
- Inventer une requête de votre choix

---

background-image: url(images/perseeHackathon2018.jpg)

???

Hackathon de Persée en 2018. Trois défis identifiés pour lesquels les données liées paraissent offrir des opportunités

Expériences de navigation

- Sortir des logiques classiques de navigation par feuilletage et de consultation par liste des résultats de recherche
- Exploiter la richesse de la typologie documentaire des corpus diffusés
- Exploiter la totalité des alignements avec les référentiels extérieurs sélectionnés

Géo-visualisation

- Exploiter graphiquement les informations géographiques présentes dans les données Persée
- Enrichir les contenus de Persée avec des informations géographiques extérieures (GeoNames, ...)

Recherche d’images

- Proposer un dispositif spécifique pour rechercher les illustrations présentes dans les documents mis en ligne sur Persée
- Inventer une nouvelle manière de visualiser et de contextualiser ces illustrations en les couplant avec des ressources extérieures

---

name: part1

# Vocabulaires et ontologies

---

## Simple Knowledge Organization System .red[SKOS]

SKOS est un vocabulaire RDF permettant de décrire des référentiels de type .red[thésaurus].

- **décrire des concepts** (en utilisant la classe principale, `skos:Concept`) 
- **exprimer les relations entre ces concepts** (relations hiérarchiques – termes plus spécifiques ou génériques – ou autres – termes en relation).
- des **propriétés pour décrire des résultats d’alignements** automatiques ou manuels entre des concepts issus de thésaurus distincts (`skos:closeMatch`, `skos:exactMatch`).

???

http://www.bnf.fr/fr/professionnels/web_semantique_boite_outils/a.web_semantique_rdf_vocabulaires.html#SHDC__Attribute_BlocArticle3BnF

---

### Exemple SKOS

```xml
<skosConcept rdf:about="http://www.ihr-tobias.org/concepts/21250/Abdication">
    <skos:prefLabel>Abdication</skos:prefLabel>
</skosConcept>
```

.footnote[exemple tiré du [thesaurus of British and Irish History](http://www.history.ac.uk/projects/digital/tobias)]

---

### Exemple SKOS

```xml
<skosConcept rdf:about="http://www.ihr-tobias.org/concepts/21250/abdication">
    <skos:prefLabel>Abdication</skos:prefLabel>
    <skos:narrower rdf:resource="http://www.ihr-tobias.org/concepts/19838/abdication_crisis_1936"/>
</skosConcept>
```

Visionner ce RDF en Turtle avec [EasyRDF](http://www.easyrdf.org/converter)

.footnote[exemple tiré du [thesaurus of British and Irish History](http://www.history.ac.uk/projects/digital/tobias)]

---

## Notion d’ontologie

Une ontologie est un ensemble de déclarations descriptives explicites à propos du monde (habituellement référée comme le domaine d’intérêt ou le sujet de l’ontologie). Par leur caractère explicite, ces descriptions satisfont plusieurs fonction :

- prévenir l’ambiguïté et l’incompréhension dans la communication (explicites)
- se comporter de manière uniforme et prévisible pour fonctionner dans un environnement logiciel

---

## Web Ontology Language (OWL)

Est un langage de schéma ou un langage de représentation de la connaissance du web sémantique. OWL permet de définir des concepts de manière à pouvoir les réutiliser. 

- **OWL (Web Ontology Language):** The schema language, or knowledge representation (KR) language, of the Semantic Web. OWL enables you to define concepts composably so that these concepts can be reused as much and as often as possible. Composability means that each concept is carefully defined so that it can be selected and assembled in various combinations with other concepts as needed for many different applications and purposes.

---

## Classes

Les classes groupent tous les individus qui partagent des propriétés pour y faire référence. Les classes représentent ainsi essentiellement des ensembles d’individus. En modélisation, les classes sont souvent employées pour dénoter l’ensemble des objets compris par un concept dans la pensée humaine : par exemple, le concept de *personne* ou de *femme*.

Hiérarchies de classes

Instances de classes (individus)

Propriétés

cf. https://www.w3.org/TR/owl2-primer/#CWhat_is_OWL_2.3F

???

@todo compléter

---

## Éditeurs d’ontologies

https://protege.stanford.edu (libre et open source)

http://owlgred.lumii.lv

--

VOWL: Visual Notation for OWL Ontologies http://purl.org/vowl/spec/

---

## TP visualiser l’ontologie FOAF

- Prendre connaissance de l’ontologie Friend Of a Friend

  [FOAF Vocabulary Specification](http://xmlns.com/foaf/spec/)

- Visualiser FOAF avec WebVOWL

  http://visualdataweb.de/webvowl/#iri=http://xmlns.com/foaf/0.1/

- Histoire de réviser un peu sa notation turtle, produisez une notice personnelle avec FOAF

- Visualiser le graphe produit avec [EasyRDF](http://www.easyrdf.org/converter)

cf. [WebVOWL: Web-based Visualization of Ontologies](http://vowl.visualdataweb.org/webvowl.html)

---

## Rappels sur la notation Turtle

Un triplets regroupe trois composantes, séparées par un espace pour éviter les ambiguïtés

------

## Notation des IRI

[Internationalized Resource Identifiers](https://tools.ietf.org/html/rfc3987) (IRIs)

- Les IRI sont encadrées par des chevrons ouvrants et fermants

  `<http://monIri.ca/ontologie#concept>`

------

## Définitions de préfixes (rappels)

Un préfixe pour un URI est défini par

`PREFIX *ident*: *IRI* .`

Exemple :

```rdf
PREFIX gl: <http://www.iro.umontreal.ca/lapalme/SPARQL#> .
```

Ce préfixe est utilisé à une déclaration pour former l’URI complet. Ainsi `gl:toto` désignera l’URI `<http://www.iro.umontreal.ca/lapalme/SPARQL#toto>`. L’identificateur de préfixe peut être vide. 

------

## Notation des triplets (rappels)

Un triplet est noté par trois URI suivis par un point. Ils désignent respectivement le sujet, le prédicat et l’objet RDF. 

`gl:s gl:p gl:q .`

L’objet peut aussi être un littéral 

`gl:s gl:p "o" .`

### Raccourcis

Lorsqu’un sujet est partagé par plusieurs triplets successifs, les paires prédicat et objet sont séparées par un point-virgule

`gl:s gl:p "o" ; gl:p1 "o1" .`

```rdf
gl:s gl:p "o" . 

gl:s gl:p1 "o1" .
```

Lorsqu’un sujet et un prédicat sont communs à plusieurs déclarations, ces dernières sont séparées par des virgules

`gl:s gl:p gl:o , "o1".`

```rdf
gl:s gl:p gl:o. 

gl:s gl:p "o1".
```

**Attention** ! dans ce contexte, les parenthèses sont utilisées pour dénoter des collections

------

## Notation des nœuds anonymes

Plusieurs notations possibles :

-  `[]`
- `_:`

La notation avec crochets permet de combiner des triplets avec les raccourcis `,` et `;`

| `[gl:p "o"] .`             | `_:b1 gl:p "o" .`                    |
| -------------------------- | ------------------------------------ |
| `[gl:p "o"] gl:q gl:o2 .`  | `_:b2 gl:p "o". _b2 gl:q gl:o2 .`    |
| `gl:s gl:p [gl:p1 gl:o]. ` | `gl:s gl:p _:b3 . _:b3 gl:p1 gl:o .` |
| `[gl:p gl:o;gl:p1 "o1"].`  | `_:b4 gl:p gl:o ._:b4 gl:p1 "o1" .`  |

------

## Constantes et littéraux

Les constantes sont des **chaînes de caractères** entourées par des guillemets simples `’` ou doubles `"`

Il est possible de **typer les littéraux** avec [XML Schema](https://www.w3.org/TR/xmlschema-2/)

- suffixe `^^` suivi immédiatement du type xsd
- déclarer le préfixe avec `@PREFIX xsd: http://www.w3.org/2001/XMLSchema-datatypes .`

```
"3"^^xsd:integer
"1.2"^^xsd:decimal
"2018-04-10T11:24:23"^^^xsd:dateTime
```

- entier `1 ≡ "1"^^xsd:integer`
- décimal `1.2 ≡ "1.2"^^xsd:decimal`
- exposant `1.2e6 ≡ "1.2e6"^^xsd:double`

Il est aussi possible d’étiqueter la langue d’une chaîne de caractères avec le suffixe `@` et un code langue ISO

- `"toto"@fr`
- `"toto"@en`

---

name: part2

# Le protocole et le langage de requête SPARQL

SPARQL est [un ensemble de recommandations du W3C](https://www.w3.org/2009/sparql/wiki/Main_Page) pour travailler des bases de triplets RDF

- un protocole
- un langage de requête et de manipulation de données

Syntaxe basée sur la définition de modèles de triplets comportant des variables

### Standards

- SPARQL 1.1 standardisé par le W3C en 2013 (ensemble de [11 recommandations](https://www.w3.org/TR/sparql11-overview/))
- SPARQL 1.0 en 2008

???

SPARQL a une syntaxe basée sur la définition de modèles de triplets comportant des variables qui doivent correspondre à des triplets de la base.

Inspiré des langages relationnels SQL, plusieurs antécédents SPARQL, RQL, TRIPLE, Xcerpt, SeRQL

---

#### SQL vs SPARQL

```sql
SELECT 	e.surname AS es,
		p.name AS pn
FROM employee e, project p
WHERE 	e.gender = 'male'
		AND p.administratorId = e.id
		AND e.surname LIKE 'N\%';
```

```sparql
PREFIX : <http://example.org/> SELECT ?sn, (?projname AS ?pn) 
WHERE {
	?e a :Employee .
	?e :surname ?sn .
	?e :gender 'male'.
	?p a :Project .
	?p :name ?pn .
	?p :administrator ? e. 
	FILTER (strstarts(?sn,'N'))
}                      
```

???

’Get projects having male administrators starting on the letter N’

---

### Les spécifications SPARQL 1.1

- [SPARQL 1.1 Overview](http://www.w3.org/TR/sparql11-overview/)
- [SPARQL 1.1 Query Language](http://www.w3.org/TR/sparql11-query/)
- [SPARQL 1.1 Update](http://www.w3.org/TR/sparql11-update/)
- [SPARQL 1.1 Service Description](http://www.w3.org/TR/sparql11-service-description/)
- [SPARQL 1.1 Federated Query](http://www.w3.org/TR/sparql11-federated-query/)
- [SPARQL 1.1 Query Results JSON Format](http://www.w3.org/TR/sparql11-results-json/)
- [SPARQL 1.1 Query Results CSV and TSV Formats](http://www.w3.org/TR/sparql11-results-csv-tsv/)
- [SPARQL Query Results XML Format (Second Edition)](http://www.w3.org/TR/rdf-sparql-XMLres/)
- [SPARQL 1.1 Entailment Regimes](http://www.w3.org/TR/sparql11-entailment/)
- [SPARQL 1.1 Protocol](http://www.w3.org/TR/sparql11-protocol/)
- [SPARQL 1.1 Graph Store HTTP Protocol](http://www.w3.org/TR/sparql11-http-rdf-update/)

---

## SPARQL Query Language

[SPARQL 1.1 Query Language](http://www.w3.org/TR/sparql11-query/)

Supposant un graphe de triplet chargé dans un service SPARQL, le Langage de requêtes SPARQL permet de formuler des requêtes qui prennent la forme de motifs de graphe plus ou moins complexes. 

### Formats des résultats

- Extensible Markup Language ([XML](http://www.w3.org/XML/)), cf. [SPARQL Query Results XML Format (Second Edition)](http://www.w3.org/TR/rdf-sparql-XMLres/)
- JavaScript Object Notation ([JSON](https://www.ietf.org/rfc/rfc4627.txt)), cf. [SPARQL 1.1 Query Results JSON Format](http://www.w3.org/TR/sparql11-results-json/)
- Comma Separated Values ([CSV](https://www.ietf.org/rfc/rfc4180.txt)), cf. [SPARQL 1.1 Query Results CSV and TSV Formats](http://www.w3.org/TR/sparql11-results-csv-tsv/)
- Tab Separated Values ([TSV](http://www.iana.org/assignments/media-types/text/tab-separated-values)), cf. [SPARQL 1.1 Query Results CSV and TSV Formats](http://www.w3.org/TR/sparql11-results-csv-tsv/)

???

Supposant un graphe de triplet chargé dans un service SPARQL, le Langage de requêtes SPARQL permet de formuler des requêtes qui prennent la forme de motifs de graphe plus ou moins complexes. 

### Formats des résultats

Afin de pouvoir échanger les résultats dans des formats lisibles par la machine, SPARQL supporte **quatre formats d’échanges** : 

- Extensible Markup Language ([XML](http://www.w3.org/XML/)), cf. [SPARQL Query Results XML Format (Second Edition)](http://www.w3.org/TR/rdf-sparql-XMLres/)
- JavaScript Object Notation ([JSON](https://www.ietf.org/rfc/rfc4627.txt)), cf. [SPARQL 1.1 Query Results JSON Format](http://www.w3.org/TR/sparql11-results-json/)
- Comma Separated Values ([CSV](https://www.ietf.org/rfc/rfc4180.txt)), cf. [SPARQL 1.1 Query Results CSV and TSV Formats](http://www.w3.org/TR/sparql11-results-csv-tsv/)
- Tab Separated Values ([TSV](http://www.iana.org/assignments/media-types/text/tab-separated-values)), cf. [SPARQL 1.1 Query Results CSV and TSV Formats](http://www.w3.org/TR/sparql11-results-csv-tsv/)

---

##### Soit, le graphe de triplets suivant

```rdf
@prefix foaf: <http://xmlns.com/foaf/0.1/> .
@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .

<http://example.org/alice#me> a foaf:Person .
<http://example.org/alice#me> foaf:name "Alice" .
<http://example.org/alice#me> foaf:mbox <mailto:alice@example.org> .
<http://example.org/alice#me> foaf:knows <http://example.org/bob#me> .
<http://example.org/bob#me> foaf:knows <http://example.org/alice#me> .
<http://example.org/bob#me> foaf:name "Bob" .
<http://example.org/alice#me> foaf:knows <http://example.org/charlie#me> .
<http://example.org/charlie#me> foaf:knows <http://example.org/alice#me> .
<http://example.org/charlie#me> foaf:name "Charlie" .
<http://example.org/alice#me> foaf:knows <http://example.org/snoopy> .
<http://example.org/snoopy> foaf:name "Snoopy"@en .
```

cf. [SPARQL 1.1 Overview](http://www.w3.org/TR/sparql11-overview/)

---

##### La requête SPARQL suivante avec SELECT

```sparql
PREFIX foaf: <http://xmlns.com/foaf/0.1/>
SELECT ?name (COUNT(?friend) AS ?count)
WHERE { 
    ?person foaf:name ?name . 
    ?person foaf:knows ?friend . 
} GROUP BY ?person ?name
```

ramène les noms des personnes et leur nombre d’amis

cf. [SPARQL 1.1 Overview](http://www.w3.org/TR/sparql11-overview/)

???

### Présentation

Exemple tiré de [SPARQL 1.1 Overview](http://www.w3.org/TR/sparql11-overview/).

Soit le graphe de triplets RDF suivant, la requête SPARQL avec SELECT ramène les noms des personnes et leur nombre d’amis

### Différences entre la spécification 1.0 et 1.1

- Comme dans la spécification précédente 1.0 de 2008, il est aussi possible de formuler des requêtes complexes avec union, des parties optionnelles (optional query parts) et des filtres (filters).
- La spécification 1.1 introduit l’agrégation de valeurs (value aggregation), les expressions de chemin  (path expressions), la possibilité de formuler des requêtes imbriquées (nested queries), etc. 
- En dehors de la clause SELECT - qui lie des variables - SPARQL supporte la clause ASK – i.e. boolean "yes/no" – et la clause CONSTRUCT – avec laquelle de nouveaux graphes RDF peuvent être construits à partir d’un résultat de requête.

Nota, possibilité de faire des requêtes fédérées sur plusieurs SPARQL endpoints cf. [SPARQL 1.1 Federated Query](http://www.w3.org/TR/sparql11-federated-query/)

---

##### Résultat JSON

```xml
<?xml version="1.0"?>
<sparql xmlns="http://www.w3.org/2005/sparql-results#">
 <head>
   <variable name="name"/>
   <variable name="count"/>
 </head>
 <results>
   <result>
     <binding name="name">
       <literal>Alice</literal>
     </binding>
     <binding name="count">
       <literal datatype="http://www.w3.org/2001/XMLSchema#integer">3</literal>
     </binding>
   </result>
   <!-- ... autant d’élément <result> que de résultats -->
 </results>
</sparql>
```

##### Résultat CSV

```csv
name,count
Alice,3
Bob,1
Charlie,1
```

---

## SPARQL Update Language

[SPARQL 1.1 Update](http://www.w3.org/TR/sparql11-update/) (non couvert dans ce cours)

- un langage de manipulation de données complet
- opérations des mise à jour (Update) qui peuvent consister en plusieurs requêtes séquentielles réalisées sur une collection de graphes
- opérations possibles sur les graphes RDF dans un entrepôt
  - mise à jour
  - création
  - suppression

???

Un langage de manipulation de données complet, à l’instar de SQL puisqu’il permet aussi de mettre à jour des graphes de triplets.

Les opérations de mise à jour (Update) peuvent consister en plusieurs requêtes séquentielles qui sont réalisées sur une collection de graphes contenue dans un entrepôt. 

Ces opérations permettent de mettre à jour, de créer et de supprimer des graphes RDF dans un entrepôt.

---

##### Exemple de mise à jour d’un graphe de triplets

````sparql
PREFIX foaf: <http://xmlns.com/foaf/0.1/> .

INSERT DATA { <http://www.example.org/alice#me> foaf:knows [ foaf:name "Dorothy" ]. } ;
DELETE { ?person foaf:name ?mbox } 
WHERE { <http://www.example.org/alice#me> foaf:knows ?person .
        ?person foaf:name ?name FILTER ( lang(?name) = "EN" ) .}
````

???

Par exemple, la requête suivante, insère un nouvel ami d’Alice dénommée Dorothy dans le graph par défaut puis supprime tous les noms des amis d’Alice qui sont en anglais.

Comme on le voit, la seconde opération peut être dépendante du résultat d’une requête sur l’entrepôt. La syntaxe utilisée dans la clause WHERE est ici dérivée du langage de requête.

---

## SPARQL Protocol

[SPARQL 1.1 Protocol](http://www.w3.org/TR/sparql11-protocol/)

- définit une manière de transférer des requêtes ou opérations de mise à jour à un service SPARQL via HTTP
- définit une manière pour faire correspondre ces requêtes à des opérations HTTP GET et POST
- définit les réponses HTTP respectives de ces requêtes

---

#### Exemple de requête HTTP

```txt
GET /sparql/?query=PREFIX%20foaf%3A%20%3Chttp%3A%2F%2Fxmlns.com%2Ffoaf%2F0.1%2F%3E%0ASELECT%20%3Fname%20%28COUNT%28%3Ffriend%29%20AS%20%3Fcount%29%0AWHERE%20%7B%20%0A%20%20%20%20%3Fperson%20foaf%3Aname%20%3Fname%20.%20%0A%20%20%20%20%3Fperson%20foaf%3Aknows%20%3Ffriend%20.%20%0A%7D%20GROUP%20BY%20%3Fperson%20%3Fname 
HTTP/1.1
Host: www.example.org
User-agent: my-sparql-client/0.1
```

???

For instance, the query from Section 3 above issued against a SPARQL query service hosted at `http://www.example.org/sparql/` could according to this specification be wrapped into an HTTP GET request (where the query string is URI-encoded):

Details about response encoding and different operations for query and update requests, as well as supported HTTP methods, are described in the Protocol specification.

### Notions

- **SPARQL Protocol client** An HTTP client (as defined by [RFC 2616](http://www.w3.org/Protocols/rfc2616/rfc2616-sec1.html#sec1.3) [[RFC2616](https://www.w3.org/TR/2013/REC-sparql11-protocol-20130321/#rfc2616)]) that sends HTTP requests for SPARQL Protocol operations. (Also known as: *client*)
- **SPARQL Protocol service** An HTTP server that services HTTP requests and sends back HTTP responses for SPARQL Protocol operations. The URI at which a SPARQL Protocol service listens for requests is generally known as a SPARQL endpoint. (Also known as: *service*)
- **SPARQL endpoint** The URI at which a SPARQL Protocol service listens for requests from SPARQL Protocol clients.
- **SPARQL Protocol operation** An HTTP request and response that conform to the protocol defined in this document.
- **RDF Dataset** A collection of a default graph and zero or more named graphs, as defined by the [SPARQL 1.1 Query Language](http://www.w3.org/TR/sparql11-query/#rdfDataset).

---

## SPARQL endpoint

L’URI à laquelle un service au protocole SPARQL écoute les requêtes d’un client SPARQL

- https://ckan.org
- https://datahub.io
- http://sparqles.ai.wu.ac.at

### Logiciels

- [SNORQL](https://github.com/kurtjx/SNORQL)

???

Plusieurs logiciels, avec ou sans GUI

@todo exemple

---

name: part3

# Notation SPARQL

---

## Syntaxe

SPARQL a une syntaxe basée sur la définition de modèles de triplets comportant des variables qui correspondent à des triplets de la base

### Types de requêtes

`SELECT`, `WHERE`, `CONSTRUCT`, `ASK`, `DESCRIBE`

### Modèle de graphe

Précédé par la clause `WHERE` ou ù

- requêtes basées sur la notion de **modèles de graphe**
- des **variables** (identificateurs précédés de `?` ou `$`) sont instanciées lorsqu’un triplet concorde avec le modèle

### Modificateurs

- `ORDER BY *variables*`
- `DISTINCT`

???

### Types de requêtes

Une requête débute par une clause qui peut comporter l’un des verbes suivants

- `SELECT *vars* WHERE *modèle*` qui retourne la liste des valeurs des variables pour lesquelles il existait des triplets dans la base qui concordaient avec le modèle de graphe.
- `CONSTRUCT *modèle1* WHERE *modèle2*` où les variables des deux modèles sont liées. Cette requête retourne une structure RDF qui regroupe les triplets de *modèle1* avec les valeurs des variables qui sont liées à des valeurs pour lesquelles il existait des triplets dans la base qui concordaient avec le *modèle2*.
- `ASK *modèle*` retourne `true` s’il existe au moins un triplet qui concorde avec le modèle et `false` sinon.
- `DESCRIBE` permet de *décrire* un ressource ou une variable mais cette description est laissée au soin de l’implantation.

### Modèle de graphe

SPARQL a une syntaxe basée sur la définition de modèles de triplets comportant des variables qui correspondent à des triplets de la base

- Les requêtes sont basées sur la notion de modèle de graphe qu’on cherchera à retrouver dans une base de triplets. 
- Dans un modèle de graphe, un triplet peut comporter des variables (i.e. des identificateurs précédés par `?` ou `$`) qui seront instanciées lorsqu’un triplet concorde au modèle en affectant une variable.

### Filtre

### Modificateurs

- `ORDER BY *variables*`
- `DISTINCT`

Les triplets étant considérés comme un ensemble, il n’est pas possible de se fier à l’ordre d’apparition des résultats. Néanmoins, on peut modifier l’ordre de la sortie avec les mots-clefs suivants :

- `ORDER BY *variables*` à la fin de la requête, trie les solutions en ordre croissant des variables; pour l’ordre décroissant, on indique `DESC(*variable*)`. On peut trier les solutions sur plusieurs clés.
- `DISTINCT` à placer immédiatement après le *verbe* (i.e. le premier mot) d’une requête pour garantir que chaque solution n’apparaîtra qu’une fois.

## Autres possibilités

SPARQL 1.1 fournit également des fonctions d’agrégation telles des sommes ou des moyennes et la possibilité de définir des variables. 

Nous ne décrivons ici que les principaux éléments de la syntaxe SPARQL. Il est également possible d’interroger plusieurs graphes ou faire des requêtes fédérées. Pour la syntaxe complète, il convient de se référer à la documentation du W3C.

Lien utile : aide-mémoire par Guy Lapalme http://www.iro.umontreal.ca/~lapalme/ift6282/SparqlRappels.html

---

## Types de requêtes

- ### .red[SELECT] – retourne une table liée (similaire à SQL)

- ### .red[ASK] – retourne vrai ou faux selon l’existence d’un pattern donné dans le graphe RDF

- ### .red[CONSTRUCT] – retourne un graphe RDF construit à partir des tables liée

- ### .red[DESCRIBE] – retourne un graphe RDF décrivant une ressource donnée

---

## Modèle de graphe

Les requêtes sont basées sur la notion de modèle de graphe qu’on cherche à retrouver dans une base de triplets. Dans un modèle de graphe, un triplet peut comporter des variables (i.e. des identificateurs précédés par `?` ou `$`) qui seront instanciées lorsqu’un triplet concorde au modèle en affectant une variable.

Un modèle de graphe est une suite de triplets entre accolades `{ }`. Une variable liée dans un triplet garde la même valeur dans tous les autres triplets où elle est utilisée dans le même modèle de graphe. Il est de plus possible d’ajouter des contraintes supplémentaires sur les triplets par un *filtre* qui peut apparaître entre des triplets dans un modèle de graphe. Par exemple, le modèle de graphe `{?s gl:p "o". ?s gl:p "o1"}` liera la variable `?s` à tous les sujets de la base de triplets qui ont comme prédicat `gl:p` et objet `"o"` et `"o1"`. Comme on peut utiliser les notations abrégées de triplets, ce modèle de graphe aurait pu aussi s’écrire `{?s gl:p "o", "o1"}`.

???

@todo revoir

---

## Notation des variables et patrons

- URI ou Littéral `?var ?une_autre_var $v`
- Nœuds vides `_:id []`

### Patrons de triplets

- Match complet 	`ex:machin ex:numero "45692"`
- Match avec une variable 	`?machin ?ex:numero "?valeur`
- Match complet 	`ex:truc ?propriete ?valeur`

---

## Modèles de graphe

- ### .red[conjonction] (séquence de motifs de graphe)

- ### .red[disjonction] (UNION pattern)

- ### .red[négation] (FILTER NOT EXISTS, MINUS)

- ### .red[conjonction conditionnelle] (OPTIONAL)

???

Graph Pattern (GP)

```sparql
# Basic Graph Pattern (BGP)
?x :p ?y .
?y :s _:a .
```

```sparql
# Group Graph Pattern (GGP)
{ ?x :p ?y . }
{ ?y :s _=a . }
```

```sparql
# Optional Graph Pattern (OGP)
?x :p ?y .
OPTIONAL { ?y :s _:a }
```

```sparql
# Alternative Graph Pattern (AGP)
{ ?x :p1 ?y . }
UNION
{ ?x :p2 ?y . }
```

```sparql
# Patterns on Named Graph
```

---

## Filtres

Syntaxe : BGP1 FILTER(boolean condition) BGP1

La clause filtre les résultats de BGP, il peut être placé n’importe où dans un BGP.

`FILTER *expression*` où `*expression*` est composée d’une combinaison des éléments suivants :

- **conversion** entre une chaîne et un type XML en appelant une fonction du nom du type `xsd:integer` ou `xsd:dateTime` sur une chaîne, une variable ou une expression
- une expression arithmétique ou logique entre parenthèses; cette expression utilise les opérateurs infixes *habituels*
- un appel à une fonction prédéfinie, p. ex. `isIRi(?x)`, `isBLANK(?x)` ou `REGEX(*string*,*pattern*)`.

Un filtre s’applique au modèle de graphe entier où il se trouve, peu importe sa position dans le graphe.

???

Fonctions de chaînes : strlen, contains, substr, concat, regex, replace

Fonction de terme RDF : isIRI, IRI, isBlank, BNODE

BGP : Basic Graph Pattern

---

### Exemple de filtres

```sparql
PREFIX dc: <http://purl.org/dc/elements/1.1/> 
SELECT ?title
WHERE { 
	?x dc:title ?title .
	?x dc:author ?author
	FILTER regex(?title, ".SPARQL") }
```

```sparql
PREFIX : <http://example.org/> 
PREFIX rdfs <http://www.w3.org/2000/01/rdf-schema#> 
SELECT ?s ?l
WHERE {
	?s :invented ?i.
	?i rdfs:label ?l 
	FILTER(regex(?l,"ˆ.ul.*") && contains(str(?s),"Cimr"))
}
```

---

## Optional

Syntaxe : GP1 OPTIONAL { GP2 }

Les résultats de GP1 sont augmentés optionnellement avec les résultats de GP2, s’il y en a.

```sparql
PREFIX : <http://example.org/> 
PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#> SELECT ?s ?i ?l
WHERE {
	?s :invented ?i. 
	OPTIONAL {
		?i rdfs:label ?l FILTER (lang(?l)="en"). 
	} OPTIONAL {
		?i rdfs:label ?l FILTER (lang(?l)="cs") 
	}
}
```

L’ordre des OPTIONALs peut être important

---

## Négation

Deux constructions MINUS vs. FILTER NOT EXISTS

````sparql
PREFIX : <http://example.org/> 
PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#
SELECT ?s1 ?i
{ 	?s1 :invented ?i.
	MINUS {
		?s2 :invented ?i . 
		FILTER(?s1 != ?s2) . }}
````

```sparql
SELECT ?s1 ?i 
{	?s1 :invented ?i.
	FILTER NOT EXISTS {
		?s2 :invented ?i .
		FILTER(?s1 != ?s2). }}
```

???

Dans le premier cas la variable ?s1 n’est pas liée dans le motif MINUS, retourne tous les inventeurs.

Dans le second cas, retourne toutes les inventions qui furent inventées par seulement un inventeur.

---

## Agrégations

- COUNT(?var), ou COUNT(DISTINCT ?var) – compte le nombre ou les occurence (distinctes) de ?var dans l’ensemble résultat
- MIN(?v), MAX(?v), SUM(?v), AVG(?v) – analogues à leur équivalents SQL
- GROUP CONCAT(?var; separator = <SEP>) AS ?group) – concatènera tous les elements dans le groupe avec le caractère séparateur donné
- SAMPLE – prend une représentant arbitraire dans le groupe

???

Usage of (?expr as ?var) alias is obligatory.

Similarly to SQL, SPARQL allows computing aggregates over particular
data groups and filter in them using GROUP BY/HAVING construct

---

### Exemple d’agrégation

```sparql
PREFIX : <http://example.org/>
PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>
SELECT (COUNT(?s) AS ?count) ?i (GROUP_CONCAT(?s;separator=",") AS
	?inventors) 
FROM :inventors 
WHERE {
	?s :invented ?i. 
}
GROUP BY ?i
HAVING (COUNT(?s) > 1)
```

(expr AS ?v) assignent de variable où expr est une expression et ?v la nouvelle variable créée

---

## Autres fonctionnalités

- ORDER BY, LIMIT, OFFSET – comme dans SQL
- FROM, FROM NAMED – employé pour spécifier des graphe par défaut ou nommés pour la requête
- SELECT DISTINCT – retire les duplication du résultat
- VALUES – variables prédéfinie spécifiant liant dans la forme tabulaire

---

name: part4

# TP Écriture de requêtes SPARQL

Utilisation dans [Twinkle](http://www.iro.umontreal.ca/~lapalme/ift6281/Twinkle.html) ?

Aide-Mémoire http://www.iro.umontreal.ca/~lapalme/ift6282/SparqlRappels.html

---

### SPARQL par l’exemple

```sparql
SELECT * 
# FROM <http://xxxx> 
WHERE { 
   ?subject ?predicate ?object 
}
```

- Sélectionner un sujet et visualiser les propriétés et les objets liés


- Identifier une URI comme valeur de , et chercher à visualiser tous les objets qui partagent le même objet
- Combiner avec une autre propriété
- Appliquer un filtre
- compter par type, etc. group by

???

@todo chg ontologie

@todo limiter quantité de résultats

```sparql
SELECT * 
WHERE { :Lyndal_Roper ?b ?c }
```

Identifier une URI comme valeur de , et chercher à visualiser tous les objets qui partagent le même objet

```sparql
SELECT * WHERE {
?historian_name ?predicate <http://dbpedia.org/class/yago/Historian110177150>
}
```

Combiner avec une autre propriété

```
SELECT ?name
WHERE {
?name ?b <http://dbpedia.org/class/yago/WikicatBritishHistorians> .
?name ?b <http://dbpedia.org/class/yago/WikicatWomenHistorians>
}
```

```
{ ?object ecrm:P108i_was_produced_by ?production .
  ?production ecrm:P9_consists_of ?date_node .
FILTER(?date >= "1580-01-01"^^xsd:date &&
         ?date <= "1600-01-01"^^xsd:date) }
```

```
PREFIX bmo: <http://www.researchspace.org/ontology/>
PREFIX skos: <http://www.w3.org/2004/02/skos/core#>
PREFIX ecrm: <http://www.cidoc-crm.org/cidoc-crm/>
PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>

SELECT ?type (COUNT(?type) as ?n)
WHERE {
  # We still need to indicate the ?object_type variable,
  # however we will not require it to match "print" this time

  ?object bmo:PX_object_type ?object_type .
  ?object_type skos:prefLabel ?type .

  # Once again, we will also filter by date
  ?object ecrm:P108i_was_produced_by ?production .
  ?production ecrm:P9_consists_of ?date_node .
  ?date_node ecrm:P4_has_time-span ?timespan .
  ?timespan ecrm:P82a_begin_of_the_begin ?date .
  FILTER(?date >= "1580-01-01"^^xsd:date &&
         ?date <= "1600-01-01"^^xsd:date)
}
# The GROUP BY command designates the variable to tally by,
# and the ORDER BY DESC() command sorts the results by
# descending number.
GROUP BY ?type
ORDER BY DESC(?n)
```

---

## Go live avec Wikidata !

---

## Enrichissement avec Isidore

---

name: part5

# Florilège d’applications du Linked Open Data

---

http://biolit.rkbexplorer.com

http://biolit.rkbexplorer.com/sparql/

???

This is one of several semantic repositories that contains and publishes RDF linked data and co-reference information, forming the underlying distributed storage model behind the [RKB Explorer](http://www.rkbexplorer.com/) initiative.

There is a lot of text in this store, so you may want to avoid doing free text searches on things like "Shakespeare" and "people"!

This repository contains data processed by Hugh Glaser as a **birthday present to Ian Davis**.

It is a very quick and dirty job of processing the data provided by [Project Gutenberg](http://www.gutenberg.org/) from [A Short Biographical Dictionary of English Literature by John W. Cousin](http://www.gutenberg.org/ebooks/13240).

---

## Quelques référentiels structurants en art

http://www.getty.edu/research/tools/vocabularies/lod/index.html

https://www.frantiq.fr

???

Historique

---

## Urbanisation des systèmes d’information du MCC

Programme [HADOC](http://www.culture.gouv.fr/Divers/Harmonisation-des-donnees-culturelles)

- [Ginco](http://data.culture.fr/thesaurus/)
- [Onoma](http://www.culture.gouv.fr/Divers/Harmonisation-des-donnees-culturelles/Referentiels/Le-referentiel-des-acteurs-historiques/ONOMA)

???

### Ginco

> #### L’harmonisation des vocabulaires
>
> Les vocabulaires scientifiques et techniques (listes d'autorités, thésaurus, nomenclatures diverses) constituent un élément fort de mise en cohérence de l'ensemble de la production documentaire du ministère. C'est pourquoi l'harmonisation des vocabulaires est au cœur du programme HADOC.
>
> **Enjeux et objectifs du projet**
>
> Utilisés pour l'indexation et la recherche, les nombreux vocabulaires scientifiques et techniques servant à la description des Biens culturels sont généralement enfermés dans les outils de production, de gestion ou de diffusion des informations documentaires. L'enjeu initial du projet d'harmonisation des vocabulaires est de les « libérer », de les faire sortir des outils en vue d'en partager l'usage entre différents métiers et applications, d'en faciliter la réutilisation et d'en faire de véritables référentiels terminologiques.
>
> **Un nouvel environnement de production des vocabulaires**
>
> L'harmonisation des outils et des formats de gestion et de diffusion constitue un prérequis au partage des vocabulaires. Ce travail est réalisé dans le cadre du **projet GINCO** (Gestion Informatisée de Nomenclatures Collaboratives et Ouvertes), qui constitue l'une des briques applicatives du programme HADOC.
>
> L'application de gestion GINCO est actuellement en cours de développement. La version 1 est d'ores et déjà disponible. Elle fournit un environnement de gestion des vocabulaires appuyé sur la norme ISO 25964-1:2011 (*Information et documentation – Thésaurus et interopérabilité avec d'autres vocabulaires – Partie 1: Thésaurus pour la recherche documentaire*). Les thésaurus ou listes d'autorité produits dans ce nouvel environnement sont exportables au format SKOS, langage de diffusion des terminologies sur la toile.
>
> L'application est développée en logiciel libre et est  [**disponible sur la forge GitHub**](https://github.com/culturecommunication/ginco)   sous licence CeCILL. [Une machine virtuelle](https://github.com/culturecommunication/ginco/blob/master/doc/VM_INSTALL.md) permettant de la tester est également disponible.
>
> **Un espace de diffusion ouvert**
>
> Les vocabulaires scientifiques et techniques qui sous-tendent la production documentaire et en garantissent la qualité constituent de plus en plus, dans le contexte du *web* sémantique, les outils indispensables une navigation intelligente. Pour en faciliter le partage et la réutilisation, le ministère a souhaité mettre à disposition ces vocabulaires en utilisant les technologies du *web* sémantique.
>
> Conçue initialement par le Service interministériel des Archives de France (SIAF), la plate-forme dite « Thésaurus W » servait à diffuser le *Thésaurus pour la description et l'indexation des archives locales anciennes, modernes et contemporaines* dans le format SKOS. L'application est en cours de reprise dans le cadre du projet GINCO pour devenir le site d'exposition de l'offre terminologique du ministère en accès ouvert. Elle est donc appelée à s'enrichir progressivement de l'ensemble des ressources terminologiques issues de l'application GINCO.
>
> Ce site d'exposition progressivement d'autres types de données, qui seront accessibles à la fois par les internautes et par les machines au moyen d'identifiants stables. Le ministère souhaite en effet accompagner l'émergence progressive des données sur le *web* de données par la mise en œuvre d'une politique d'[**identification pérenne**](http://www.culture.gouv.fr/Divers/Harmonisation-des-donnees-culturelles/Ouverture-des-donnees/L-identification-perenne-des-ressources) des ressources.
>
> http://www.culture.gouv.fr/Divers/Harmonisation-des-donnees-culturelles/Referentiels/Les-vocabulaires-scientifiques-et-techniques/L-harmonisation-des-vocabulaires

Voir aussi http://www.culture.gouv.fr/Divers/Harmonisation-des-donnees-culturelles/Referentiels/Les-vocabulaires-scientifiques-et-techniques/L-application-GINCO

### Onoma

Depuis 2015

> #### Le référentiel des acteurs historiques
>
> **Présentation du projet**
>
> Le projet« ONOMA » constitue un des projets du programme HADOC, programme dédié à l'harmonisation de la production des données culturelles. Le programme HADOC a été lancé en 2008. Il implique toutes les directions métier du ministère.
> Le besoin de mettre en place un référentiel d'Acteurs (auteurs, créateurs, producteurs, personnalités intervenant dans le cycle de vie d'un Bien culturel) a été identifié dès le lancement du programme HADOC.
>
> Dès 2010, un groupe de travail multidisciplinaire et interinstitutionnel a travaillé, à partir de l'analyse de l'existant, à la définition du périmètre du référentiel et à l'élaboration d'une première version d'un modèle de données partagé qui a ensuite été intégré au Modèle harmonisé pour la production des données culturelles, dit « modèle HADOC». La phase de mise en œuvre avait été reportée dans une seconde étape.
> Le projet « ONOMA » porte précisément sur la création du référentiel de données. L'objectif est de passer de répertoires ou de listes d'auteurs propres aux applications et/ou aux métiers à un ensemble de données de référence partagé par une large communauté d'utilisateurs.
>
> Le projet comprend la réalisation de l'outil de gestion des données de référence et la reprise des données existant dans les différents corpus.
> Comme le programme HADOC, le projet « ONOMA » implique toutes les directions métier du ministère, ainsi que des représentants des établissements publics et du monde de la recherche.
>
> **Objectifs du projet**
>
> Il s'agit de construire autour des « acteurs » identifiables dans les ressources documentaires un référentiel transverse, un noyau commun d'informations structurées, normalisées et validées en vue de répondre à un double besoin :
>
> - en production, faciliter le travail d'identification des acteurs, alléger les tâches de saisie et de mise à jour des informations, accroître la complétude et la fiabilité des données, limiter les redondances d'information ;
> - en consultation et recherche, permettre d'accéder à une description unique d'un acteur à partir d'une oeuvre ou d'une production à laquelle il est associé ; rebondir, à partir des données sur l'acteur, sur l'ensemble des ressources (oeuvres et productions, données de biographie) auxquelles il est associé ; permettre des parcours de navigation aisés entre les acteurs et les biens culturels. Le projet s'appuiera sur les apports des technologies du web social et du web sémantique pour :
> - d'une part, enrichir les données du référentiel par la contribution et la collaboration, en développant entre le Ministère, ses partenaires et les usagers une démarche de co-construction;
> - d'autre part, mettre à disposition ces données dans l'écosystème des données ouvertes et liées (Linked Open Data), afin d'en favoriser le partage, l'appropriation et la réutilisation et de faciliter la découverte d'informations par les usagers.
>
> De ce point de vue, le projet s'inscrit résolument dans la démarche et les objectifs définis dans la Feuille de route stratégique « Métadonnées culturelles et transition web 3.0 » du Ministère.
>
> ***** *du grec ancien désignant un nom propre*
>
> http://www.culture.gouv.fr/Divers/Harmonisation-des-donnees-culturelles/Referentiels/Le-referentiel-des-acteurs-historiques/ONOMA

---

## Quelques référentiels structurants en bibliothéconomie

- http://id.loc.gov/
- https://rvmweb.bibl.ulaval.ca
- http://rameau.bnf.fr/informations/projint.htm#skos
- https://www.idref.fr
- http://www.isni.org
- https://orcid.org
- https://viaf.org

???

- Répertoires unifiés de vedettes matières
- Listes d’autorités
- Identifiants

---

## Référentiels géographiques

- http://www.geonames.org
- http://pleiades.stoa.org
- http://commons.pelagios.org

---

## SKOS Play

http://labs.sparna.fr/skos-play/?lang=fr

???

SPARNA

---

## Recherche Isidore

https://www.rechercheisidore.fr

---

## Data.bnf.fr

http://data.bnf.fr/semanticweb

http://data.bnf.fr/opendata

http://data.bnf.fr/sparql/

http://api.bnf.fr

???

Publié en 2011, ouverture des données et d’adoption des standards du web sémantique. Agnès Simon, chef de produit data.bnf.fr,

cf. <http://www.bnf.fr/fr/professionnels/anx_pro_videos/a.video_cnfpt_data.html>

Le projet data.bnf.fr s'inscrit dans une démarche d'ouverture des données telle qu’elle a été définie par le W3C dans la perspective du Web sémantique ou Web de données (Open Linked Data). Ceci avec un double objectif :

- objectif de visibilité et d’accessibilité : rassemble des données issues de différentes bases de la Bnf
- objectif de diffusion : données ouvertes juridiquement avec licence libre et techniquement sous les formats du web sémantique

Pb spécifique des catalogues de la Bnf

- http://data.bnf.fr/semanticweb modèle qui s’inspire grandement de FRBR, pb éditions d’une même œuvre. exemple Voltaire, dictionnaire philo, etc. Retrouve aussi des liens vers d’autres documents, autres expression ou version de l’œuvre *Nicomède*.
- http://data.bnf.fr/opendata

Mise en œuvre qui suppose plusieurs choses. Importation de données en provenance de diverses bases ou sources de données dont importe des données structurées. Ces différentes sources sont soumises à des traitements automatisés pour les enrichir ou les regrouper. Ici utilisation de [CubicWeb](http://www.cubicweb.org/)

À l’issue de ce traitement, on obtient des données structurées pour les humains et dans des formats standards du web sémantique.

Pour y parvenir, utilisation des référentiels d’autorités. Utilisation d’identifiants uniques et de liens.

- des URI pour les ressources, actionnables et pérennes
- une exposition RDF en « Linked open data » pour les données de data.bnf.fr, disponible pour chaque page (par négociation de contenu) et pour toute la base
- un service SPARQL endpoint pour interroger les données

Données publiques sous licence libre pour permettre leur réutilisation par simple déclaration légère. Plusieurs possibilité de récupérations : par dump, par l’intermédiaire d’une API ou un SPARQL endpoint.

—> Susciter des réutilisations pour des usages nouveaux, échanger des données avec le monde de la recherche, le monde pédagogique ou du tourisme

—> Créer des liens et récupérer un certain nombre de ressources vers Wikipédia ou DBpédia pour fournir des vignettes ou biographies sur un auteur par exemple.

### OpenCat

Prototype développé dans le cadre d’un appel à projet innovant du MCC. Pour objectif de croiser les données de la Bnf, avec les données de la bibliothèque de Fresnes et des données extérieures.

Cette expérimentation de la BnF vise à encourager la réutilisation de ses données bibliographiques et d’autorité par les bibliothèques publiques, avec les outils du web de données, permettant d'enrichir les catalogues et d’offrir des nouveaux services. Le prototype réalisé sert de démonstrateur à des fins de recherche et de développement dans le contexte de coopérations nationales.

- évaluer catalogue au modèle FRBR
- récupération de données complémentaires (vignettes, ressources numériques, références extérieures complétant notices de catalogues publics)

[L'expérimentation OpenCat](http://www.bnf.fr/fr/professionnels/web_donnees_applications_bnf/a.opencat.html)

### Les identifiants : ISNI, ISSN et ARK

Si des identifiants de référence sont utilisés de manière conforme à leur usage dans de multiples bases de données distinctes, il devient aisé de relier ces données entre elles. A ce titre, les identifiants constituent un levier majeur du web de données.

[ISBN, ISSN, ISNI, ARK](http://www.bnf.fr/fr/professionnels/issn_isbn_autres_numeros.html)

### Objectifs (en 2015)

- Intégrer totalité des auteurs des catalogues
- reverser traitements automatiques dans le catalogue général et poursuivre sa FRBRisation
- poursuivre le travail de liens vers des sites extérieurs (Wikipédia, archives, musées)

Cf. https://youtu.be/lSdGiBBgp1I

---

## PIAAF (Pilote d’interopérabilité pour les autorités archivistiques françaises) 

<http://piaaf.demo.logilab.fr/>

Ontologie RiC-O (Records in Contexts - Ontology)

???

Ce mot pour dire que l’équipe projet PIAAF (Pilote d’interopérabilité pour les autorités archivistiques françaises) à récemment mis en ligne à l’adresse suivante :

un démonstrateur (preuve de concept) réalisé avec les technologies du web sémantique, pour démontrer qu’il est possible :

- de représenter en RDF, en veillant à la précision, à l’exactitude et à l’utilisabilité des triplets obtenus, des métadonnées archivistiques produites de différentes manières et selon diverses perspectives (données d’autorité encodées en fichiers XML/EAC-CPF et parties d’instruments de recherche en XML/EAD 2002) ;
- d’enrichir les triplets obtenus en créant de nouveaux triplets, qu’il s’agisse de procéder à des alignements ou d’établir de nouvelles relations par inférence ;
- de produire une interface de recherche et d’exploration analytique et graphique qui soit dynamique, ergonomique et signifiante, sans sacrifier la granularité informationnelle ni la lisibilité.

Ce projet expérimental a été réalisé par les Archives nationales, la Bibliothèque nationale de France, le Service interministériel des Archives de France au ministère de la Culture et la société Logilab. Les Archives nationales en ont assuré la direction.

Il a donc permis une première expérimentation qualitative de la sémantisation de métadonnées archivistiques réelles (fichiersEAC-CPF et parties d’instruments de recherche en EAD) selon le modèle
conceptuel RiC (Records in Contexts) et l’ontologie correspondante RiC-O (Records in Contexts - Ontology), en cours de construction au sein du Conseil international des archives. Les technologies du Web sémantique et de data visualisation ont été employées pour vérifier la faisabilité et l’utilité de la
transformation de ces fichiers en jeux de données, pour vérifier les gains en expressivité, les possibilités de construction de réseaux de relations, l’intérêt de l’interconnexion des données des trois partenaires institutionnels, l’utilité de leur visualisation en graphe.

Ses résultats ouvrent des perspectives intéressantes pour les institutions partenaires et pour toute entité ayant la responsabilité de documents d’archives et qui serait intéressée par l’emploi des technologies du web de données.

Les scripts et librairies développés dans le cadre du projet seront prochainement mis à disposition sous licence libre.

Le démonstrateur est un prototype, par définition imparfait.

En attendant le bilan détaillé du projet, il inclut des pages de présentation sur les enjeux et l’historique du projet, sur sa réalisation et sur le contenu du triplestore.
Vous y trouverez aussi un tutoriel (accessible en cliquant sur "Utiliser le prototype" en haut à droite).

Notez qu’il a été testé essentiellement avec des versions récentes de Firefox (>= 57) et Chrome (>= 60). 

Pour contacter l’équipe projet, vous pouvez utiliser l’adresse de messagerie ’[projet-piaaf.archives-nationales@culture.gouv.fr](mailto:projet-piaaf.archives-nationales@culture.gouv.fr)’

---

## Biblissima

http://beta.biblissima.fr

- http://doc.biblissima-condorcet.fr/vademecum-biblissima
- http://doc.biblissima-condorcet.fr/ontologie-biblissima
- http://data.biblissima.fr
- http://demos.biblissima-condorcet.fr/snorql/
- http://demos.biblissima-condorcet.fr/atelier-rdf-eusebe/
- http://demos.biblissima-condorcet.fr/florus/#rdf-florus

???

Bibliothèque virtuelle des bibliothèques, ce portail vous invite à découvrir l’histoire d’une partie des textes et livres qui ont été écrits, traduits, enluminés, collectionnés ou inventoriés depuis l’Antiquité jusqu’au XVIIIe siècle.

### Périmètre

Le portail Biblissima est destiné à constituer un point d’entrée de référence sur le patrimoine écrit du Moyen Age et de la Renaissance en Occident, du VIIIe au XVIIIe siècle.

Il propose un **accès unifié** à un ensemble de données numériques sur les manuscrits, incunables et imprimés anciens provenant des neuf équipes partenaires du consortium Biblissima. L’utilisateur peut notamment y consulter :

- des documents numérisés issus de Gallica (BnF), de la BVMM (IRHT-CNRS) et de nombreuses autres bibliothèques numériques à travers le monde grâce aux protocoles IIIF,
- des catalogues et bases de données spécialisées de diverses natures (provenances, iconographie, textes, reliures etc.),
- et, à terme, des éditions électroniques de textes (inventaires de bibliothèques anciennes, glose ordinaire de la Bible, sermons).

Diverses sources de données, utilisation d’un format pivot XML

## Fonctionnalités

Le portail est accessible à travers une interface web conviviale, facile d’utilisation et d’interrogation, intégrant trois fonctionnalités majeures : 

- **un moteur de recherche à facettes**, qui permet d’interroger les données et d’accéder à différents types de pages web reliées entre elles par des liens (manuscrit ou imprimé, lieu, personne ou collectivité, collection historique, oeuvre, inventaire, etc.). On peut ainsi, par rebonds successifs, suivre la transmission d’un texte, retracer l’histoire d’une bibliothèque ancienne...
- **des visualisations de données** : accès par cartes (lieux d’origine, vie d’un livre) et représentations en graphes (vie d’une oeuvre)
- **un visualiseur d’images (« Mirador »)**, capable d’afficher à distance les documents numérisés provenant de plusieurs bibliothèques numériques à travers le monde, et **conçu comme un véritable espace de travail autour des images**. A partir du portail, l’utilisateur peut ainsi constituer sa propre collection de documents, puis composer, sauvegarder et partager son environnement de visualisation personnalisé.

## Exposition des données

### Référentiels

Biblissima dispose de plusieurs **référentiels d’autorités** pour les différents types de données présentes dans le cluster : personnes, collectivités, établissements de conservation, œuvres, lieux. Ils sont pourvus d’identifiants stables, de formes préférentielles, de formes alternatives (graphies présentes dans les bases partenaires), des notes issues des bases partenaires ou du Catalogue général de la BnF et d’alignements vers des référentiels extérieurs.

Biblissima crée aussi un **référentiel de cotes de manuscrits et d’imprimés** (identifiant unique et stable, forme préférentielle), qui ont fait l’objet d’un travail de mise en correspondance et d’harmonisation afin de fusionner les données sur un même manuscrit ou imprimé ancien issues de différentes bases. 

Ces référentiels seront à terme disponibles sur le portail Biblissima.

### Web sémantique

Les données du cluster Biblissima seront exposées en **RDF**, sous la forme d’exports accessibles depuis les pages de chaque entité, de dumps et d’un triple store.

La structuration des données RDF sera conforme à [l’ontologie Biblissima](http://doc.biblissima-condorcet.fr/ontologie-biblissima) (basée sur le CIDOC CRM et FRBRoo).

### Web sémantique

Les données du cluster Biblissima seront exposées en **RDF**, sous la forme d’exports accessibles depuis les pages de chaque entité, de dumps et d’un triple store.

La structuration des données RDF sera conforme à [l’ontologie Biblissima](http://doc.biblissima-condorcet.fr/ontologie-biblissima) (basée sur le CIDOC CRM et FRBRoo).

http://beta.biblissima.fr/fr/a-propos

---

## International Image Interoperability Framework (IIIF)

http://iiif.io/

### Exemples

- http://doc.biblissima-condorcet.fr/introduction-iiif
- [Démo Mirador de Biblissima](http://demos.biblissima-condorcet.fr/mirador/)
- https://iiif.bodleian.ox.ac.uk
- http://projectmirador.org/

Pour en savoir plus https://kinow.github.io/scico-2017/#/

???

l’initiative internationale IIIF pour l’interopérabilité des images (International Image Interoperability Framework - IIIF).

L’espace de travail Mirador est un outil de visualisation et de manipulation d’images haute résolution, configurable et partageable selon les besoins de l’utilisateur. Il est possible d’y ajouter des documents à partir du portail en utilisant la fonction de "panier" (Ma sélection) accessible depuis les listes de résultats et la page d’un livre manuscrit ou imprimé. Une fois sa sélection de documents effectuée, l’utilisateur peut ouvrir les documents choisis dans Mirador, constituer son propre environnement de visualisation, puis enregistrer sa session et la partager par le biais d’un lien.

- Exemple de session : [beta.biblissima.fr/mirador?key=bMw0Db1d1YCE15Jox1xA&version=2](http://beta.biblissima.fr/mirador?key=bMw0Db1d1YCE15Jox1xA&version=2).
- [Démo Mirador de Biblissima](http://demos.biblissima-condorcet.fr/mirador/)

---

## API de présentation de IIIF

![](images/objects-all.png)

???

## API de présentation

> ### Structure
>
> The Presentation API describes “just enough metadata to drive a remote viewing experience”. This metadata is a **IIIF Manifest**. The Manifest represents the thing. A book. A painting. A film. A sculpture. An opera. A long-playing record. A manuscript. A map. An aural history field recording. A videocassette of a public information film. A laboratory notebook. A diary. All of these things would be represented by a IIIF Manifest. You publish IIIF manifests for each of your objects. 
>
> A manifest is what a IIIF viewer loads to display the object. A manifest could be used to generate a web page for the object. A manifest could be loaded into an annotation tool, or a IIIF editing environment to be used as source material in the creation of a new manifest.
>
> If the object the manifest represents is a photograph, there might only be one conceptually distinct view of it that we wish to convey via the Presentation API, to end up on a user's screen. For many objects there is more than one view. Even for a painting, it might be important to include the back of the canvas frame. And for books, manuscripts and much archive material, each page, leaf, folio or sheet is one or two separate views - in its normal state we can't look at all of them at once, the model conveys them as a sequence of distinct views. Depending on how the book has been captured and how we want to model it, we might have one view per page, or one view per double page spread, and extra views for inserts or supplementary material.
>
> cf. image
>
> ### Canvas pour les vues
>
> These views are represented by **Canvases**. A Manifest contains one or more **Sequences** of **Canvases**. A canvas is not the same as an image. The canvas is an abstraction, a virtual container for content. It's analogous to a PowerPoint slide; an initially empty container, onto which we "paint" content. If we want to provide a sequence of images to a book reading application, or for viewing paintings, the concept of a canvas may seem like an extra layer of complexity. It's not much more complicated to do it this way, but it is much more flexible and powerful.
>
> *The canvas is the abstract space; we provide an image to paint the canvas*
>
> The Canvas keeps the content separate from the conceptual model of the page of the book, or the painting, or the movie. The content can be images, blocks of text, video, links to other resources, and the content can be positioned precisely on the canvas. By including a Canvas in a Manifest, you provide a space on which you and others can **annotate** content. For image-based content the PowerPoint analogy is clear: the Canvas is a 2D rectangular space with an aspect ratio. The height and width properties of a canvas define the aspect ratio and provide a simple coordinate space. This coordinate space allows the creator of the manifest to associate whole or parts of content with whole or parts of canvases, and for anyone else to make their own annotations in that space.
>
> This means that you can provide more than one representation of a view. You might have a painting photographed in natural light and in X-ray. You might have a manuscript that was captured to microfilm, and your initial presentation of the material uses images derived from the microfilm. Later, you go back and photograph some of the folios at high resolution, maybe those with illuminations. You can update the content associated with a Canvas without having to retract the canvas and the other content you might already have associated with it.
>
> You may have a manuscript represented as a sequence of Canvases, but for some of those Canvases you have no image at all - the page was known to exist, but is now lost. You may still have text content associated with the Canvas - transcriptions from a copy, commentary, or other notes. The fact that for this particular folio you have no photographic representation doesn't stop you modelling it in the Manifest and associating content with it - just not an image in this case.
>
> ### Annotation
>
> All association of content with a canvas is done by **annotation**. The IIIF Presentation API is built on the Open Annotation standard, which has now become the W3C Web Annotation Data Model. At its simplest, the Web Annotation Data Model is a formalised way of linking resources together:
>
> *An annotation is considered to be a set of connected resources, typically including a body and target, and conveys that the body is related to the target. The exact nature of this relationship changes according to the intention of the annotation, but the body is most frequently somehow "about" the target. This perspective results in a basic model with three parts, depicted below. The full model supports additional functionality, enabling content to be embedded within the annotation, selecting arbitrary segments of resources, choosing the appropriate representation of a resource and providing styling hints to help clients render the annotation appropriately.*
>
> A simple annotation might be an association between a page of a manuscript and an article about that page elsewhere on the web. Or, in the context of a bookreader or viewer, it might be a comment on or transcription of a particular part of the page, or the whole page. This notion of annotations as commentary or transcriptions is familiar:
>
> But in IIIF, the image itself is one just of the pieces of content annotating the abstract canvas. There may be multiple images, there may be no images at all. This diagram shows that all the content a user ever sees rendered by a viewer - images, text and other content - is associated with the virtual space of the canvas via the mechanism of annotation.
>
> source https://resources.digirati.com/iiif/an-introduction-to-iiif/

Shared Canvas, espace abstrait utilisé pour construire une vue de l’objet (cf. diapositives powerpoint)

### Properties

- Descriptive

  - `label`, nom de la ressource

  - `description`, résumé textuel

  - `thumbnail`, aperçu visuel

  - `metadata`, paires noms-valeurs

    ex: label:"Creates", value:"1300"

- Rights

  - `licence`, lien vers la description de la licence
  - `attribution`, texte à affiche
  - `logo`, image à présenter

- Linking

  - `service`, point d’entrée du service additionnel
  - `sseAlso`, ressource de métadonnées
  - `related`, resource à présenter aux utilisateurs

Voir aussi 

- https://www.slideshare.net/azaroth42/iiif-presentation-api
- https://resources.digirati.com/iiif/an-introduction-to-iiif/ +++
- https://youtu.be/EE1YskDrzPs

---

## Pundit

http://thepund.it

- [exemple d’utilisation](http://net7.github.io/pundit2/)

### Recommandations du Web Annotation Working Group du W3C 

- [Web annotation Data Model](https://www.w3.org/TR/annotation-model/), 
- [Web Annotation Vocabulary](https://www.w3.org/TR/annotation-vocab/), 
- [[Web Annotation Protocol](https://www.w3.org/TR/annotation-protocol/)

### Autre implémentation

- [Hypothes.is](https://hypothes.is)

---

## ResearchSpace

https://public.researchspace.org

---

## Semantic MediaWiki

http://www.aifb.kit.edu/web/Semantic_MediaWiki_Software/en

Artatlas

???

Semantic MediaWiki (SMW) is an open-source project to which many people and organisations have contributed. The SMW project was founded by Markus Krötzsch and Denny Vrandecic during their work at the Institute AIFB at Karlsruhe Institute of Technology (KIT). There is an active developer and user community with yearly conferences (SMWCon) in Europe and America. People at AIFB are involved in SMW in various projects. Also, AIFB organises a yearly SMW-Seminar. Various extensions to SMW have been developed by AIFB employees. For instance, the Semantic Web Browser and Semantic Project Management.

---

## OmekaS

https://github.com/omeka/omeka-s

???

Plate-forme de publication Web dédiées aux collections numériques du patrimoine culturel) sort de sa version bêta et maintenant disponible en v1 stabilisée.

---

### OpenRefine

https://github.com/OpenRefine/OpenRefine/releases/tag/2.8

### Tag

<http://tag.ontotext.com/>

### Karma, a Data Integration Tool

http://usc-isi-i2.github.io/karma/



???

### OpenRefine

https://github.com/OpenRefine/OpenRefine/releases/tag/2.8

### Tag

<http://tag.ontotext.com/

pour nettoyer et enrichir des jeux de données) sort sa version 2.8 (après 2–3 ans sans nouvelle version stabilisée)

Outil “**tag**” de l’entreprise ontotext permettant de faire de l’extraction d’entités nommées via #DBpédia et#wikidata

### Karma, a Data Integration Tool

http://usc-isi-i2.github.io/karma/



---

## Mondeca Labs

http://labs.mondeca.com

------

https://datalift.org

---

# Biblio et références

http://www.iro.umontreal.ca/~lapalme/ift6282/SparqlSyntaxe.html

http://www.iro.umontreal.ca/~lapalme/ift6282/SparqlRappels.html

## Blogs

https://bibliotheques.wordpress.com

## À voir 

http://aksw.org/Projects/CubeViz.html

wtf https://ruben.verborgh.org/publications/